{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d74f559-1116-482e-892f-03f18d86ade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import prada\n",
    "import xgboost as xgb\n",
    "import veritas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e700ba60-24ae-4c2c-b6f5-6186e085d3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cached /home/laurens/prada_data/Spambase.h5\n"
     ]
    }
   ],
   "source": [
    "d = prada.Spambase()\n",
    "d.load_dataset()\n",
    "d.robust_normalize()\n",
    "dtrain, dtest = d.split(0.6)\n",
    "dtest, dvalid = dtest.split(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6ab92c-0ac3-4ac3-a526-ac8341d27c53",
   "metadata": {},
   "source": [
    "# Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a8e44354-4acc-48ba-8011-c52268779239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_conversion: no problems detected (rel_tol 0.0001)\n",
      "mtrain 0.945 mvalid 0.933 mtest 0.934\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(\n",
    "    n_estimators=10,\n",
    "    max_leaves=8\n",
    ")\n",
    "clf.fit(dtrain.X, dtrain.y)\n",
    "at = veritas.get_addtree(clf, silent=True)\n",
    "\n",
    "veritas.test_conversion(at, dtrain.X.to_numpy().astype(veritas.FloatT), clf.predict_proba(dtrain.X)[:,1])\n",
    "\n",
    "mtrain = dtrain.metric(clf)\n",
    "mvalid = dvalid.metric(clf)\n",
    "mtest = dtest.metric(clf)\n",
    "\n",
    "print(f\"mtrain {mtrain:.3f} mvalid {mvalid:.3f} mtest {mtest:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a18bb1fa-6535-4253-b49e-ca7837cb4147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformx_lookup(t):\n",
    "    K = t.num_nodes()\n",
    "    lookup = np.zeros((K, K-1), dtype=bool) # exclude root\n",
    "\n",
    "    for l in t.get_leaf_ids():\n",
    "        n = l\n",
    "        while not t.is_root(n):\n",
    "            lookup[l, n-1] = 1\n",
    "            n = t.parent(n)\n",
    "\n",
    "    return lookup\n",
    "\n",
    "def transformx_for_tree(X, t):\n",
    "    lookup = transformx_lookup(t)\n",
    "    N = X.shape[0]\n",
    "    K = t.num_nodes()\n",
    "    xx = np.zeros((N, K-1), dtype=np.float32)\n",
    "\n",
    "    for i, l in enumerate(t.eval_node(X)):\n",
    "        xx[i, :] = lookup[l, :]\n",
    "\n",
    "    return xx\n",
    "\n",
    "def transformx(X, at):\n",
    "    xx = np.hstack([\n",
    "        transformx_for_tree(X, t) for t in at\n",
    "    ])\n",
    "    return xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "68e5205a-cbe8-4e71-8dd0-a181a1ad6edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxtrain = torch.from_numpy(transformx(dtrain.X, at))\n",
    "yytrain = torch.from_numpy(dtrain.y.to_numpy().reshape(-1, 1).astype(np.float32))\n",
    "xxvalid = torch.from_numpy(transformx(dvalid.X, at))\n",
    "yyvalid = torch.from_numpy(dvalid.y.to_numpy().reshape(-1, 1).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3052dd58-c2b0-4e00-8b41-73ae0a4fa9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, at):\n",
    "        super().__init__()\n",
    "        self.width = sum(t.num_nodes()-1 for t in at)\n",
    "        self.lin = nn.Linear(self.width, at.num_leaf_values())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.sigmoid(self.lin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c5cad493-4808-4327-91b4-aa1507c1ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "79e1d00f-e64f-43dd-a8ca-b9c518780f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 0.1699610948562622\n",
      "199 0.16998697817325592\n",
      "299 0.16999202966690063\n",
      "399 0.16999799013137817\n",
      "499 0.17000199854373932\n",
      "599 0.16999542713165283\n",
      "699 0.16999460756778717\n",
      "799 0.16999605298042297\n",
      "899 0.1699967384338379\n",
      "999 0.16999608278274536\n",
      "1099 0.16999590396881104\n",
      "1199 0.16999614238739014\n",
      "1299 0.1699962019920349\n",
      "1399 0.16999611258506775\n",
      "1499 0.16999609768390656\n",
      "1599 0.16999612748622894\n",
      "1699 0.16999612748622894\n",
      "1799 0.16999612748622894\n",
      "1899 0.16999611258506775\n",
      "1999 0.16999611258506775\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=0.04)\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    ypred = model(xxtrain)\n",
    "\n",
    "    # Compute and print loss.\n",
    "    loss = F.binary_cross_entropy(ypred, yytrain)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables it will update (which are the learnable\n",
    "    # weights of the model). This is because by default, gradients are\n",
    "    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to model\n",
    "    # parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d9605cd5-b452-482c-9ad8-6c8b3976e529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mtrain 0.94402, mvalid 0.92464\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    ypred_tr = model(xxtrain)\n",
    "    ypred_va = model(xxvalid)\n",
    "\n",
    "acc_tr = np.mean((ypred_tr > 0.5).numpy().flatten() == dtrain.y.to_numpy())\n",
    "acc_va = np.mean((ypred_va > 0.5).numpy().flatten() == dvalid.y.to_numpy())\n",
    "\n",
    "print(f\"mtrain {acc_tr:.5f}, mvalid {acc_va:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4677add-08ee-4dc7-a383-f19f1ca9501d",
   "metadata": {},
   "source": [
    "# Getting the weights back to the trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0451f8b4-c448-460b-8985-43059aed4d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mtrain 0.94511, mvalid 0.93261\n",
      "mtrain 0.94402, mvalid 0.92464\n"
     ]
    }
   ],
   "source": [
    "def update_addtree_weights(at, model):\n",
    "    weights = model.lin.weight.detach().numpy().ravel()\n",
    "    offset = 0\n",
    "\n",
    "    at.set_base_score(0, model.lin.bias)\n",
    "\n",
    "    for m, t in enumerate(at):\n",
    "        lookup = transformx_lookup(t)\n",
    "        K = t.num_nodes()-1\n",
    "        ws = weights[offset:offset+K]\n",
    "        offset += K\n",
    "        for l in t.get_leaf_ids():\n",
    "            v = ws.dot(lookup[l, :])\n",
    "            #vo = t.get_leaf_value(l, 0)\n",
    "            t.set_leaf_value(l, 0, v)\n",
    "            #print(f\"{m:4d}{l:4d}: {vo:+6.3f} -> {v:+6.3f} ({abs(vo-v):+6.3f})\")\n",
    "\n",
    "atc = at.copy()\n",
    "update_addtree_weights(atc, model)\n",
    "\n",
    "for m in [at, atc]:\n",
    "    ypred_tr = m.eval(dtrain.X.to_numpy().astype(veritas.FloatT))\n",
    "    ypred_va = m.eval(dvalid.X.to_numpy().astype(veritas.FloatT))\n",
    "    acc_tr = np.mean((ypred_tr > 0.0).flatten() == dtrain.y.to_numpy())\n",
    "    acc_va = np.mean((ypred_va > 0.0).flatten() == dvalid.y.to_numpy())\n",
    "\n",
    "    print(f\"mtrain {acc_tr:.5f}, mvalid {acc_va:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fa612bb7-9f3d-4148-9e18-ba50fbaa7566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node(id=0, split=[F26 < 0.00862069], sz=15, left=1, right=2)\n",
      "├─ Node(id=1, split=[F16 < 0.340426], sz=13, left=3, right=4)\n",
      "│  ├─ Node(id=3, split=[F22 < 0.314286], sz=7, left=5, right=6)\n",
      "│  │  ├─ Node(id=5, split=[F51 < 1.12688], sz=3, left=7, right=8)\n",
      "│  │  │  ├─ Leaf(id=7, sz=1, value=[-0.168157])\n",
      "│  │  │  └─ Leaf(id=8, sz=1, value=[0.146894])\n",
      "│  │  ├─ Node(id=6, split=[F16 < 0.170213], sz=3, left=9, right=10)\n",
      "│  │  │  ├─ Leaf(id=9, sz=1, value=[0.316405])\n",
      "│  │  │  └─ Leaf(id=10, sz=1, value=[0.209658])\n",
      "│  ├─ Node(id=4, split=[F24 < 0.0718232], sz=5, left=11, right=12)\n",
      "│  │  ├─ Node(id=11, split=[F11 < 0.781457], sz=3, left=13, right=14)\n",
      "│  │  │  ├─ Leaf(id=13, sz=1, value=[0.57572])\n",
      "│  │  │  └─ Leaf(id=14, sz=1, value=[0.396323])\n",
      "│  │  └─ Leaf(id=12, sz=1, value=[0.208413])\n",
      "└─ Leaf(id=2, sz=1, value=[-0.166717])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(atc[len(atc)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4e5ec9ba-34bc-4e16-b92f-2a3529b0831c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node(id=0, split=[F26 < 0.00862069], sz=15, left=1, right=2)\n",
      "├─ Node(id=1, split=[F16 < 0.340426], sz=13, left=3, right=4)\n",
      "│  ├─ Node(id=3, split=[F22 < 0.314286], sz=7, left=5, right=6)\n",
      "│  │  ├─ Node(id=5, split=[F51 < 1.12688], sz=3, left=7, right=8)\n",
      "│  │  │  ├─ Leaf(id=7, sz=1, value=[-0.0827581])\n",
      "│  │  │  └─ Leaf(id=8, sz=1, value=[0.29238])\n",
      "│  │  ├─ Node(id=6, split=[F16 < 0.170213], sz=3, left=9, right=10)\n",
      "│  │  │  ├─ Leaf(id=9, sz=1, value=[0.35356])\n",
      "│  │  │  └─ Leaf(id=10, sz=1, value=[-0.00801275])\n",
      "│  ├─ Node(id=4, split=[F24 < 0.0718232], sz=5, left=11, right=12)\n",
      "│  │  ├─ Node(id=11, split=[F11 < 0.781457], sz=3, left=13, right=14)\n",
      "│  │  │  ├─ Leaf(id=13, sz=1, value=[0.37056])\n",
      "│  │  │  └─ Leaf(id=14, sz=1, value=[0.0510146])\n",
      "│  │  └─ Leaf(id=12, sz=1, value=[-0.256735])\n",
      "└─ Leaf(id=2, sz=1, value=[-0.318531])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(at[len(at)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90284fa-88e0-400a-ab4b-afc210345029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
